---
title: ": STAT 4701 Project 4"
author: "Shuni Fang, Robert Minnich, Patrick Rogan, Hiroaki Suzuki, Gary Sztajnman, Yaoru Yi"
date: "May 13, 2016"
output: html_document
---

#Introduction
Throughout this report we will be exploring a data set that consists of State of the Union speeches from George Washington (1790) to Barack Obama (2016). Within this report there were several areas that we wanted to explore such as visualizing the speeches, how the speeches might be related in terms of Political Party and Presidential Rating, and also how the speeches evolve in time. We will show this through multiple methods including dimension reduction, sentimental analysis, word frequencies and cosine similarities. We will start with visualizations using different methods of dimension reduction to explore Political Party, Presidential Rating and Year of the speech.

<center>
<IMG SRC="figs/US-Presidents-Games.jpg" float = "left" ALT="image">
</center>

```{r,warning=F,echo = FALSE,  Eval = TRUE, message= FALSE, results="hide", fig.align='center'}
library(knitr)
library(rgl)
knit_hooks$set(webgl = hook_webgl)
library(bpca)
library(ggfortify)
library(ggplot2)
library(RColorBrewer)

#Read in and load CSV
df = read.csv("data/3D_Plotting.csv")
df = df[,-1]
df = df[complete.cases(df),]
df1 = df[,c(1,2,3)]
df2 = df[,c(4,5,6)]
df3 = df[,c(7,8,9)]

#Read in Labels, Parties and Colors
names = df[,10]
colors_party = as.character(df[,11])
colors_year = df[,12]

```

##Document Term Matrix Visualization
Text can be an extremely difficult data type to visualize. Within a document term matrix (DTM) there can be tens of thousands of words, associated with only a handful of documents. This creates a very sparse matrix that is hard to conceptualize. One way to combat the sparsity is to use dimension reduction techniques in order to see if relationships are available. 

Three separate forms of reduction were used on this data set, which includes Principal Component Analysis (PCA) ,Multidimensional Scaling (MDS) and t-distributed Stochastic Neighbor Embedding(T-SNE). We want to compare these different methods to try and determine if the speeches of the presidents can help indicate different attributes.

All three of these forms used only the Document Term Matrix and did reductions from that data to two dimensions.

This data includes each president's speech, so one president can appear in the data multiple times.
###Political Party
First we look into the Political Party to see if we can find any distinct relationships between how a party speaks during their Presidential Speeches. This could be possible because typically the government has always been divided into two ideals, power for the states, and power for the federal government.
<center>
<IMG SRC="figs/Dimension_Plots_Party.png" float = "left" ALT="image">
</center>
<br>
From this figure we can see that for PCA we can see some clustering of the Democrats and the Republicans. W can also see the Federalist, Democrat-Republican in a right group on the lower left portion of the PCA Cluster. For MDS we scan see some similar groups as PCA but for T-SNEW there is no visible pattern between political parties.

We further explore this area by investigating the sentiment of presidential speeches by party. Here we only compare the modern Democratic and Republican parties which have existed in their current incarnations since 1852.  

<center>
<IMG SRC="figs/S_Party.png" float = "left" ALT="image">
</center>

Sentiment score was calculated by taking all words in a speech, determining the sentiment of each individual word based on two corpora of positive and negative words, summing all positive words and negative words, and then taking the difference between total positive sentiment and total negative sentiment words.  

While there does note appear to be any inherent differences in the distributions of sentiment between the two parties, we do note that the vast majority of speeches appear to contain a majority of positive words.

###Presidential Rating
We also wanted to investigate the speeches towards their overall presidential rating. It could be that Presidents who are doing well, have a positive outlook on the country and have a more positive message. We computed the quantiles of the presidential ratings an then grouped them by the different groups of percentiles as indicated by the legend.

<center>
<IMG SRC="figs/Dimension_Plots_Rating.png" float = "left" ALT="image">
</center>
<br>
We can see in PCA and MDS that there does seem to be a tight grouping on the +50% of the presidents and somewhat for the -50%. T-SNE again does not show any significant pattern. 

We then look at the relationship between Sentiment Score and Ratings Points.

<center>
```{r,warning=F,echo = FALSE, Eval = TRUE, message= FALSE}
require('dplyr')
require('SnowballC')
require('tm')
require('xlsx')
require('zoo')
require('plyr')
require('plotly')

load("data/dtm.Rda")
load("data/tdm.Rda")
load("data/docs.Rda")
information = read.csv('data/President_Info3.csv', header=T)

# Sentiment analysis based on: 
# 
# http://www.r-bloggers.com/sentiment-analysis-on-donald-trump-using-r-and-tableau/
#   With positive/negative words from:
#   
#   Minqing Hu and Bing Liu. "Mining and Summarizing Customer Reviews." 
#       Proceedings of the ACM SIGKDD International Conference on Knowledge 
#       Discovery and Data Mining (KDD-2004), Aug 22-25, 2004, Seattle, 
#       Washington, USA

positives= readLines("data/positive-words.txt")
negatives = readLines("data/negative-words.txt")

# Merge strings of speech content to one string containing all the words in the speech
fullSpeeches = list()
for (i in 1:length(docs)){
  fullSpeeches[i] = paste(docs[[i]]$content, sep="", collapse=" ")
}

# Calculate simple sentiment scores. This function compares the words 
# in a speech against two corpora of positive and negative words and then
# takes the difference between positive and negative words
sentiment_scores = function(speech, positive_words, negative_words){
  scores = c()
  for (i in 1:length(speech)){
    word_list = strsplit(as.character(speech[i]), " +")
    words = unlist(word_list)
    # compare words to the dictionaries of positive & negative terms
    positive.matches = match(words, positive_words)
    negative.matches = match(words, negative_words)
    # get the position of the matched term or NA
    # we just want a TRUE/FALSE
    positive_matches = !is.na(positive.matches)
    negative_matches = !is.na(negative.matches)
    # final score
    scores[i] = sum(positive_matches) - sum(negative_matches)
  }
  return(scores)
}

# Finally we scatter speech sentiment against presidential popularity 
information$allScores = sentiment_scores(fullSpeeches, positives, negatives)

f <- list(
  size = 18
)
x <- list(
  title = "Sentiment Score",
  titlefont = f
)
y <- list(
  title = "Rating Points",
  titlefont = f
)

sentPop <- plot_ly(data = information, x = allScores, y = Rating.points, mode = "markers",
        color = Political.Party)  %>% 
        layout(xaxis = x, yaxis = y, title = "Ratings Points vs Sentiment Score")
sentPop
```
</center>
<br>

Here we do not see an obvious relationship; the variables are only slightly correlated with $\rho$ = -0.180. Based on this result and the results of PCA, MDS and T-SNE analysis, we believe that any relationship that may exist between Rating Points and the nature of State of the Union address would be due to more complex features than the simple measure of the difference between the number of positive and negative sentiment words.  

###Presidential Year
Presidential year was also a potentially interesting area to look into. The presidents of the united states have had many different challenges throughout the history of America and could show significant patterns in the words that they choose for the speech.

The legend below shows the color of the points based on year: 
<center>
<IMG SRC="figs/Dimension_Plots_Years_Legend.png" float = "left" ALT="image">
<IMG SRC="figs/Dimension_Plots_Years.png" float = "left" ALT="image">
</center>
<br>
We can see from this image we can see much better groupings than for the Political Parties and the Ratings. This is most likely due to the trends, problems and speech changes over time and is most likely reflected in the words that the have chosen. 

To get an idea of what words might be causing this change we can look at an Importance Plot that was generated using Random Forests, in order to predict the year based on which words they have chosen in their speech. Many of these point to some notion of time, either the word itself, or how old the word usage may be. For instance, today addressing the Congressional body as "Gentleman" is very incorrect because in today's government it is made up of men and women, while in the earlier history it was made up of only men. We can see Korea, which could be allow the Random Forests to identify presidents that were leading the country during the Korean War.  

<center>
<IMG SRC="figs/ImportancePlot_Years_50.png" float = "left" ALT="image">
</center>

```{r,warning=F,echo = FALSE,  Eval = TRUE, message= FALSE, results="hide", fig.align='center'}
names = df[,10]

names = as.character(names)
for(i in 1:length(names)){
  names[i] = tail(unlist(strsplit(names[i]," ")),n=1)
}

```

We also wanted to investigate this in the 3rd dimension. This was done to see if there were any more patterns that could be visualized within the time dimensionality of the speeches. T-SNE was no longer included because no visible patterns were seen in the two dimensional plots.

The darker the color, the older the speech. 

####Pan to Zoon, Click and drag to rotate
<center>
<IMG SRC="figs/Dimension_Plots_Years_Legend.png" float = "left" ALT="image">
</center>
<center>
```{r webgl=TRUE, echo = FALSE,  Eval = TRUE, message= FALSE, results="hide", fig.align='center'}
padding = 0.1
zoom = 0.65
#type = "s"
size = 5


#Create boundaries for each plot
xmin1 = min(df1$MDS1) + padding
ymin1 = min(df1$MDS2) + padding
zmin1 = min(df1$MDS3) + padding
xmax1 = max(df1$MDS1) + padding
ymax1 = max(df1$MDS2) + padding
zmax1 = max(df1$MDS3) + padding

xlim1 = c(xmin1,xmax1)
ylim1 = c(ymin1,ymax1)
zlim1 = c(zmin1,zmax1)

xmin2 = min(df2$PCA1) + padding
ymin2 = min(df2$PCA2) + padding
zmin2 = min(df2$PCA3) + padding

xmax2 = max(df2$PCA1) + padding
ymax2 = max(df2$PCA2) + padding
zmax2 = max(df2$PCA3) + padding

xlim2 = c(xmin2,xmax2)
ylim2 = c(ymin2,ymax2)
zlim2 = c(zmin2,zmax2)


xmin3 = min(df3$TSN1) + padding
ymin3 = min(df3$TSN2) + padding
zmin3 = min(df3$TSN3) + padding

xmax3 = max(df3$TSN1) + padding
ymax3 = max(df3$TSN2) + padding
zmax3 = max(df3$TSN3) + padding

xlim3 = c(xmin3,xmax3)
ylim3 = c(ymin3,ymax3)
zlim3 = c(zmin3,zmax3)

open3d()
#Create space for 2 plots
mfrow3d(1, 2, sharedMouse = TRUE, parent = NA)
next3d(current = NA, clear = TRUE, reuse = F)
plot3d(df1,col = colors_year, size = size, xlim = xlim1, ylim = ylim1, zlim = zlim1)
title3d("MDS")

#Second Plot
next3d(current = NA, clear = TRUE, reuse = F)
plot3d(df2,col = colors_year, size = size)
title3d("PCA")


```
</center>
As before we can see some clustering between the different years of the speeches. MDS however has enough spread where we plotted MDS only, along with the names of the presidents at each speech.

The darker the color, the older the speech. 

####Pan to Zoon, Click and drag to rotate
<center>
<IMG SRC="figs/Dimension_Plots_Years_Legend.png" float = "left" ALT="image">
</center>
<center>
```{r webgl=TRUE, echo = FALSE,  Eval = TRUE, message= FALSE, results="hide", fig.align='center'}

#3D Plotting
open3d()
zoom = 0.65
type = "p"

#Set parameters of plotting including text and point size
size = 10
text_size = 0.5
font = "FreeMono.ttf"

#Create Plot
plot3d(df1,col = colors_year, size = size, type = type)
#Create Text on Plot
text3d(df1, texts = names,cex= text_size, col = "black",useFreeType = TRUE,adj = 1.5)
#Title
title3d("MDS")
#Set View
view3d( theta = 0, phi = -60)
```
</center>

We can see that the more recent presidents, Obama, Bush and Clinton are very close to each other for all of their speeches. They are interestingly closer to the older presidents (Jefferson, Washington, Adams etc) than many of the other presidents throughout history.

The outliers of the plot are also interesting. Truman, Taft, Carter, Polk, which exist very far from the large cluster of presidents. While researching these presidents nothing in particular set them apart from the others. Some unique facts about them though are that Truman was president during World War 2, Taft became Chief Justice of the Supreme Courts, Polk based his campaign on a promise not re-run as president, and Carter negotiated peace talks between Egypt and Israel.

We conclude this analysis by investigating the impact of poor economic conditions with the sentiment of the speech. We looked at all of the speeches from 1857 to present (the time period for which we have macroeconomic data for the United States) and determined which of these speeches were given in periods of economic recession. 

<center>
<IMG SRC="figs/S_Econ.png" float = "left" ALT="image">
</center>

Much like our sentiment analysis of speech by political party, we see that almost all speeches contain many more positive words than negative ones. These two analyses together are indicative of the unrelentingly positive tone of presidential speeches.  

###Decode: Top 10 frequent words

In the previous part, we confirmed that some presidents are clustered while some are not. Visualizing the top 10 words from each presidents' speeches in a heat map shows the fact that some words appear frequently over years. For instance,'will', 'govern', 'nation' are high frequency words over years. And 'work', 'job', 'secure' are new top words that appear in President Barack Obama's speeches. 

(In each pixel box, readers will see information of president, word and its frequency. The X-axis didn't show all words due to the plot size, but readers are able to see the detailed information when hovering over the heat map.)
<br />
<br />
<center>
```{r,warning=F,echo = FALSE, Eval = TRUE, message= FALSE}
library(ggplot2)
library(plotly)
load("data/top10word_matrix.Rda")
word_union <- colnames(top10word_matrix)
president_names <- rownames(top10word_matrix)

heatm <- plot_ly(z = top10word_matrix, type = "heatmap",x = word_union,
                 y=president_names,colorbar = list(title = "word count"))%>%
  layout(margin = list(l = 150,b = 100), xaxis=list(title="words"), yaxis=list(title="presidents"), title = "Top 10 words of presidents' speech")
heatm
```
</center>

##Text analysis of Republican and Democrat
```{r, echo=FALSE, warning=FALSE, message=FALSE}
if (!require("wordcloud")) {
  install.packages("wordcloud")
}
if (!require("dplyr")) {
  install.packages("dplyr")
}
if (!require("scales")) {
  install.packages("scales")
}
if (!require("tm")) {
  install.packages("tm")
}
if (!require("proxy")) {
  install.packages("proxy")
}
if (!require("htmlTable")) {
  install.packages("htmlTable")
}

#setwd("C:\\Users\\HS\\Desktop\\school\\classes\\VIS\\HW_TEXT\\git2\\Edav-Text\\")

load("data/dtm.Rda")
load("data/tdm.Rda")

information = read.csv('data/President_Info3.csv', header=T)

index_republican = information$index[which(information$Political.Party == "Republican")]
index_democrat = information$index[which(information$Political.Party == "Democrat")]

dtm_republican = dtm[index_republican, ]
tdm_republican = tdm[, index_republican]

dtm_democrat = dtm[index_democrat, ]
tdm_democrat = tdm[, index_democrat]

```

Here, we would like to compare difference between Democratic Party and Republican Party. 
We looked at 88 speeches of presidents at Republican, and 84 speeches of presidents at Democrat.

Here are TOP30 words that were used at speeches of Republican.
<p style="text-align: left; font-size:20px; font-weight:bold;">Words frequency of Republican</p>
```{r echo=FALSE, warning=FALSE, message=FALSE, fig.align='center'}
mfreq_r = colSums(as.matrix(dtm_republican))
mfreq_r_df = data.frame(word=names(mfreq_r),freq=mfreq_r)
mfreq_r_df = mfreq_r_df[order(mfreq_r_df$freq, decreasing=TRUE), ]
mfreq_r_df = mfreq_r_df[1:30, ]
mfreq_r_df = data.frame(id=c(1:30), word=mfreq_r_df$word, freq=mfreq_r_df$freq)
ggplot(mfreq_r_df, aes(x = reorder(word, id), y = freq)) +
  geom_bar(stat = "identity") +
  xlab("Words") +
  ylab("Frequency") +
  theme(axis.text.x=element_text(size=12,color='black',fac='bold.italic',angle=45,hjust=0.5))
```

Here are TOP30 words that were used at speeches of Democrat
<p style="text-align: left; font-size:20px; font-weight:bold;">Words frequency of Democrat</p>
```{r echo=FALSE, warning=FALSE, message=FALSE, fig.align='center'}
mfreq_d = colSums(as.matrix(dtm_democrat))
mfreq_d_df = data.frame(word=names(mfreq_d),freq=mfreq_d)
mfreq_d_df = mfreq_d_df[order(mfreq_d_df$freq, decreasing=TRUE), ]
mfreq_d_df = mfreq_d_df[1:30, ]
mfreq_d_df = data.frame(id=c(1:30), word=mfreq_d_df$word, freq=mfreq_d_df$freq)
ggplot(mfreq_d_df, aes(x = reorder(word, id), y = freq)) +
  geom_bar(stat = "identity") +
  xlab("Words") +
  ylab("Frequency") +
  theme(axis.text.x=element_text(size=12,color='black',fac='bold.italic',angle=45,hjust=0.5))
```

As we can see above, TOP 3 words were "will"", "state", "govern" at both Republican and Democrat. 
In addition, we can see that almost same words such as as "congress", and "American" were used at both parties.

By using Word Cloud, we can see similarities between both parties visually.

<p style="text-align: left; font-size:20px; font-weight:bold;">Wordcloud of Republic</p>
```{r echo=FALSE, warning=FALSE, message=FALSE, fig.align='center'}
# republic
set.seed(111)
min_freq = 500
wordcloud(names(mfreq_r),mfreq_r,
          min.freq=min_freq,
          scale=c(4,0.5),
          colors=brewer.pal(8, "Dark2"),
          random.color=FALSE, 
          random.order=FALSE)
```

<p style="text-align: left; font-size:20px; font-weight:bold;">Wordcloud of Democrat</p>
```{r echo=FALSE, warning=FALSE, message=FALSE, fig.align='center'}
# democrat
set.seed(111)
min_freq = 450
wordcloud(names(mfreq_d),mfreq_d,
          min.freq=min_freq,
          scale=c(4,0.5),
          colors=brewer.pal(8, "Dark2"),
          random.color=FALSE, 
          random.order=FALSE)
```

Here, we will see similarity of speeches between Democrat and Republican by using cosine similarity. Cosine similarity can show the similarity between two vectors, and can be expressed in a range from 0 to 1. 
```{r, echo=FALSE, warning=FALSE, message=FALSE}
## compare similarity of documents between republic and democratic
# tdm_republican_mat <- as.matrix(tdm_republican)
# colnames(tdm_republican_mat) = index_republican
# tdm_democrat_mat <- as.matrix(tdm_democrat)
# colnames(tdm_democrat_mat) = index_democrat
# 
# tdm_merge_mat = merge(tdm_republican_mat, tdm_democrat_mat, by = "row.names")
# tdm_merge_mat = tdm_merge_mat[, 2:dim(tdm_merge_mat)[2]]
# cosine_dist_mat <- as.matrix(dist(t(tdm_merge_mat), method = "cosine"))
# 
# 
# tmp_row = c(0)
# tmp_col = c(0)
# tmp_fre = c(0)
# tmp_which = c("")
# for(i in 1:dim(cosine_dist_mat)[1]) {
#   for(j in i:dim(cosine_dist_mat)[1]) {
#     tmp_row[length(tmp_row)+1] = i
#     tmp_col[length(tmp_col)+1] = j
#     tmp_val = ""
#     tmp_which[length(length)+1] = 
#     tmp_fre[length(tmp_fre)+1] = cosine_dist_mat[i,j]
#   }
# }
# #cosine_dist_ranking_df = data.frame(pair=tmp_pair_index, freq=tmp_frequency)
# cosine_dist_ranking_df = data.frame(row=tmp_row, col=tmp_col, freq=tmp_fre)
# 
# cosine_dist_ranking_df_rank = cosine_dist_ranking_df[order(cosine_dist_ranking_df$freq, decreasing=TRUE), ]
# cosine_dist_ranking_df_rank_top20 = cosine_dist_ranking_df_rank[1:20, ]
# 
# 
# which_party_row = c()
# which_party_col = c()
# for(i in 1:dim(cosine_dist_ranking_df_rank)[1]) {
#   if ( cosine_dist_ranking_df_rank[c(i), 'row'] %in% index_democrat ) {  
#     which_party_row[length(which_party_row) + 1] = "Democratic"
#   } else {
#     which_party_row[length(which_party_row) + 1] = "Republican"
#   }
#   if ( cosine_dist_ranking_df_rank[c(i), 'col'] %in% index_democrat ) {  
#     which_party_col[length(which_party_col) + 1] = "Democratic"
#   } else {
#     which_party_col[length(which_party_col) + 1] = "Republican"
#   }  
# }
# 
# cosine_dist_ranking_df_rank_merged = cbind(cosine_dist_ranking_df_rank, 
#                                            data.frame(row_party=which_party_row), 
#                                            data.frame(col_party=which_party_col)
#                                            )
# save(cosine_dist_ranking_df_rank_merged, file="cosine_dist_ranking_df_rank_merged.Rda")
load("data/cosine_dist_ranking_df_rank_merged.Rda")

# html_output_cosine = cosine_dist_ranking_df_rank_merged[1:30, ]
# 
# for(i in 1:dim(html_output_cosine)[1]) {
#   html_output_cosine[c(i), "name1"] = paste(
#     as.character(information[information$index == html_output_cosine[c(i), "row"], ]$name), 
#     as.character(html_output_cosine[c(i), "row_party"]),
#     sep = "/"
#     )
#   html_output_cosine[c(i), "name2"] = paste(
#     as.character(information[information$index == html_output_cosine[c(i), "col"], ]$name), 
#     as.character(html_output_cosine[c(i), "col_party"]), 
#     sep = "/")
# }
#save(html_output_cosine, file="html_output_cosine.Rda")
load("data/html_output_cosine.Rda")

d_d = mean( cosine_dist_ranking_df_rank_merged[ (cosine_dist_ranking_df_rank_merged$row_party == "Democratic") &
                                    (cosine_dist_ranking_df_rank_merged$col_party == "Democratic")  , ]$freq )

r_r = mean( cosine_dist_ranking_df_rank_merged[ (cosine_dist_ranking_df_rank_merged$row_party == "Republican") &
                                            (cosine_dist_ranking_df_rank_merged$col_party == "Republican")  , ]$freq )

r_d = mean( cosine_dist_ranking_df_rank_merged[ ((cosine_dist_ranking_df_rank_merged$row_party == "Democratic") &
                                            (cosine_dist_ranking_df_rank_merged$col_party == "Republican")) |
                                            ((cosine_dist_ranking_df_rank_merged$row_party == "Democratic") &
                                               (cosine_dist_ranking_df_rank_merged$col_party == "Republican"))
                                          , ]$freq )
```

<p style="text-align: left; font-size:20px; font-weight:bold;">Top 30 cosine similarity</p>
```{r echo=FALSE, warning=FALSE, message=FALSE, fig.align='center'}
# output of the ranking of cosine similarity
htmlTable(html_output_cosine[1:30, c("name1", "name2", "freq")], rnames = c(1:30))
```

As we can see above, top row is between Democrat and Democrat, but from second row to ninth row, there are combinations between Republican and Democrat. It is interesting to see that Martin Van Buren(Democratic party) has lots of high similarities between many other presidents. The average cosine similarities of speeches between Democrat and Democrat is `r d_d`, while the cosine similarities between Republican and Republican is `r r_r`. The cosine similarities between Republican and Democrat is `r r_d`.


Before executing this analysis, we thought that we could see the clear difference between Democrat and Republican in terms of contents of speeches. According to bar plots and cosine similarities, contents themselves do not have major difference, if we see speeches from 1790 to 2016. From this results, other factors besides contents of speeches might also be related.

#Conclusion
Throughout this report we have explored many different methods of understanding textual data. We have seen visualizations using dimension reduction, sentiment analysis and word counts allowing us to gain different perspectives on the information contained in these documents. Many different insights have been discussed and we can see that some of the approaches allow for the discovery of new features, such as dimension reduction and sentiment analysis. These features could help with a machine learning task such as classification or predicting the year.  
